{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting yolov3/configs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yolov3/configs.py\n",
    "#================================================================\n",
    "#\n",
    "#   File name   : configs.py\n",
    "#   Author      : PyLessons\n",
    "#   Created date: 2020-06-04\n",
    "#   Website     : https://pylessons.com/\n",
    "#   GitHub      : https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3\n",
    "#   Description : yolov3 configuration file\n",
    "#\n",
    "#================================================================\n",
    "\n",
    "# YOLO options\n",
    "YOLO_DARKNET_WEIGHTS        = \"model_data/yolov3.weights\"\n",
    "YOLO_DARKNET_TINY_WEIGHTS   = \"model_data/yolov3-tiny.weights\"\n",
    "YOLO_COCO_CLASSES           = \"model_data/coco.names\"\n",
    "YOLO_STRIDES                = [8, 16, 32]\n",
    "YOLO_IOU_LOSS_THRESH        = 0.5\n",
    "YOLO_ANCHOR_PER_SCALE       = 3\n",
    "YOLO_MAX_BBOX_PER_SCALE     = 100\n",
    "YOLO_INPUT_SIZE             = 416\n",
    "#YOLO_INPUT_SIZE             = 800\n",
    "YOLO_ANCHORS                = [[[10,  13], [16,   30], [33,   23]],\n",
    "                               [[30,  61], [62,   45], [59,  119]],\n",
    "                               [[116, 90], [156, 198], [373, 326]]]\n",
    "# Train options\n",
    "TRAIN_YOLO_TINY             = False\n",
    "TRAIN_SAVE_BEST_ONLY        = True # saves only best model according validation loss (True recommended)\n",
    "TRAIN_SAVE_CHECKPOINT       = False # saves all best validated checkpoints in training process (may require a lot disk space) (False recommended)\n",
    "#TRAIN_CLASSES               = \"mnist/mnist.names\"\n",
    "TRAIN_CLASSES               = \"dataset/LEs/LEs_name.txt\"\n",
    "#TRAIN_ANNOT_PATH            = \"mnist/mnist_train.txt\"\n",
    "TRAIN_ANNOT_PATH            = \"dataset/LEs/LEs_train.txt\"\n",
    "TRAIN_LOGDIR                = \"log\"\n",
    "TRAIN_CHECKPOINTS_FOLDER    = \"checkpoints\"\n",
    "TRAIN_MODEL_NAME            = \"yolov3_LE800\"\n",
    "TRAIN_LOAD_IMAGES_TO_RAM    = False # faster training, but need more RAM\n",
    "#TRAIN_BATCH_SIZE            = 8\n",
    "TRAIN_BATCH_SIZE            = 2 \n",
    "TRAIN_INPUT_SIZE            = 416\n",
    "TRAIN_DATA_AUG              = True\n",
    "TRAIN_TRANSFER              = False\n",
    "TRAIN_FROM_CHECKPOINT       = False # \"checkpoints/yolov3_custom_2\"\n",
    "TRAIN_LR_INIT               = 1e-4\n",
    "TRAIN_LR_END                = 1e-6\n",
    "TRAIN_WARMUP_EPOCHS         = 2\n",
    "TRAIN_EPOCHS                = 100\n",
    "\n",
    "# TEST options\n",
    "TEST_ANNOT_PATH             = \"dataset/LEs/LEs_test.txt\"\n",
    "TEST_BATCH_SIZE             = 4\n",
    "TEST_INPUT_SIZE             = 416\n",
    "TEST_DATA_AUG               = False\n",
    "TEST_DECTECTED_IMAGE_PATH   = \"\"\n",
    "TEST_SCORE_THRESHOLD        = 0.3\n",
    "TEST_IOU_THRESHOLD          = 0.45\n",
    "\n",
    "\n",
    "#YOLOv3-TINY WORKAROUND\n",
    "if TRAIN_YOLO_TINY:\n",
    "    YOLO_STRIDES            = [16, 32, 64]    \n",
    "    YOLO_ANCHORS            = [[[10,  14], [23,   27], [37,   58]],\n",
    "                               [[81,  82], [135, 169], [344, 319]],\n",
    "                               [[0,    0], [0,     0], [0,     0]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from yolov3.dataset import Dataset\n",
    "from yolov3.yolov3 import Create_Yolov3, YOLOv3, decode, compute_loss\n",
    "from yolov3.utils import load_yolo_weights#, load_tiny_yolo_weights\n",
    "from yolov3.configs import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset/LEs/LEs_name.txt', 416)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_CLASSES, TRAIN_INPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-10 08:05:50.633349: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-07-10 08:05:50.729147: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb152cb8750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-10 08:05:50.729175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 173, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 38, in main\n",
      "    trainset = Dataset('train')\n",
      "  File \"/Users/home/Documents/Research/repos/TensorFlow-2.x-YOLOv3/yolov3/dataset.py\", line 38, in __init__\n",
      "    self.annotations = self.load_annotations(dataset_type)\n",
      "  File \"/Users/home/Documents/Research/repos/TensorFlow-2.x-YOLOv3/yolov3/dataset.py\", line 63, in load_annotations\n",
      "    raise KeyError(\"%s does not exist ... \" %image_path)\n",
      "KeyError: '/Users/home/Documents/Research/repos/TensorFlow-2.x-YOLOv3/star/star_train/000852.jpg does not exist ... '\n"
     ]
    }
   ],
   "source": [
    "# !python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Darknet_weights = YOLO_DARKNET_WEIGHTS\n",
    "if TRAIN_YOLO_TINY:\n",
    "    TRAIN_MODEL_NAME = TRAIN_MODEL_NAME+\"_Tiny\"\n",
    "    Darknet_weights = YOLO_DARKNET_TINY_WEIGHTS\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: pass\n",
    "\n",
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')\n",
    "\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_TRANSFER:\n",
    "    Darknet = Create_Yolov3(input_size=YOLO_INPUT_SIZE)\n",
    "    load_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "    #load_tiny_yolo_weights(Darknet, Darknet_weights) # use darknet weights\n",
    "\n",
    "yolo = Create_Yolov3(input_size=YOLO_INPUT_SIZE, training=True, CLASSES=TRAIN_CLASSES)\n",
    "if TRAIN_FROM_CHECKPOINT:\n",
    "    try:\n",
    "        yolo.load_weights(TRAIN_FROM_CHECKPOINT)\n",
    "    except ValueError:\n",
    "        print(\"Shapes are incompatible, transfering Darknet weights\")\n",
    "        TRAIN_FROM_CHECKPOINT = False\n",
    "\n",
    "if TRAIN_TRANSFER and not TRAIN_FROM_CHECKPOINT:\n",
    "    for i, l in enumerate(Darknet.layers):\n",
    "        layer_weights = l.get_weights()\n",
    "        if layer_weights != []:\n",
    "            try:\n",
    "                yolo.layers[i].set_weights(layer_weights)\n",
    "            except:\n",
    "                print(\"skipping\", yolo.layers[i].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "def train_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "        # update learning rate\n",
    "        # about warmup: https://arxiv.org/pdf/1812.01187.pdf&usg=ALkJrhglKOPDjNt6SHGbphTHyMcT0cuMJg\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()\n",
    "        \n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        \n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 step:    2/6, lr:0.000017, giou_loss:  50.20, conf_loss:1838.61, prob_loss:  58.16, total_loss:1946.98\n",
      "epoch: 0 step:    3/6, lr:0.000025, giou_loss:  37.20, conf_loss:1716.71, prob_loss:  41.22, total_loss:1795.13\n",
      "epoch: 0 step:    4/6, lr:0.000033, giou_loss:  48.72, conf_loss:1692.52, prob_loss:  58.57, total_loss:1799.81\n",
      "epoch: 0 step:    5/6, lr:0.000042, giou_loss:  70.51, conf_loss:1601.04, prob_loss:  82.68, total_loss:1754.23\n",
      "epoch: 0 step:    0/6, lr:0.000050, giou_loss:  48.39, conf_loss:1526.08, prob_loss:  53.62, total_loss:1628.08\n",
      "epoch: 0 step:    1/6, lr:0.000058, giou_loss:  50.93, conf_loss:1493.49, prob_loss:  59.10, total_loss:1603.51\n",
      "\n",
      "\n",
      "giou_val_loss:  27.11, conf_val_loss:1830.61, prob_val_loss:  32.78, total_val_loss:1890.50\n",
      "\n",
      "\n",
      "epoch: 1 step:    2/6, lr:0.000067, giou_loss:  62.22, conf_loss:1476.86, prob_loss:  73.52, total_loss:1612.60\n",
      "epoch: 1 step:    3/6, lr:0.000075, giou_loss:  54.02, conf_loss:1435.04, prob_loss:  65.05, total_loss:1554.11\n",
      "epoch: 1 step:    4/6, lr:0.000083, giou_loss:  45.44, conf_loss:1401.59, prob_loss:  52.08, total_loss:1499.11\n",
      "epoch: 1 step:    5/6, lr:0.000092, giou_loss:  44.84, conf_loss:1368.19, prob_loss:  52.13, total_loss:1465.16\n",
      "epoch: 1 step:    0/6, lr:0.000100, giou_loss:  30.06, conf_loss:1336.61, prob_loss:  34.31, total_loss:1400.98\n",
      "epoch: 1 step:    1/6, lr:0.000100, giou_loss:  53.72, conf_loss:1299.01, prob_loss:  63.98, total_loss:1416.70\n",
      "\n",
      "\n",
      "giou_val_loss:  25.63, conf_val_loss:1817.93, prob_val_loss:  31.13, total_val_loss:1874.69\n",
      "\n",
      "\n",
      "epoch: 2 step:    2/6, lr:0.000100, giou_loss:  56.68, conf_loss:1257.67, prob_loss:  67.86, total_loss:1382.22\n",
      "epoch: 2 step:    3/6, lr:0.000100, giou_loss:  50.58, conf_loss:1235.62, prob_loss:  59.52, total_loss:1345.72\n",
      "epoch: 2 step:    4/6, lr:0.000100, giou_loss:  46.16, conf_loss:1161.39, prob_loss:  50.45, total_loss:1258.00\n",
      "epoch: 2 step:    5/6, lr:0.000100, giou_loss:  54.01, conf_loss:1154.31, prob_loss:  64.06, total_loss:1272.38\n",
      "epoch: 2 step:    0/6, lr:0.000100, giou_loss:  38.21, conf_loss:1114.99, prob_loss:  44.02, total_loss:1197.22\n",
      "epoch: 2 step:    1/6, lr:0.000100, giou_loss:  36.99, conf_loss:1050.05, prob_loss:  43.50, total_loss:1130.55\n",
      "\n",
      "\n",
      "giou_val_loss:  26.32, conf_val_loss:1801.27, prob_val_loss:  31.66, total_val_loss:1859.26\n",
      "\n",
      "\n",
      "epoch: 3 step:    2/6, lr:0.000100, giou_loss:  58.05, conf_loss:1042.14, prob_loss:  69.54, total_loss:1169.73\n",
      "epoch: 3 step:    3/6, lr:0.000100, giou_loss:  57.48, conf_loss: 966.34, prob_loss:  64.61, total_loss:1088.43\n",
      "epoch: 3 step:    4/6, lr:0.000100, giou_loss:  34.70, conf_loss: 954.66, prob_loss:  42.12, total_loss:1031.47\n",
      "epoch: 3 step:    5/6, lr:0.000100, giou_loss:  55.57, conf_loss: 904.78, prob_loss:  63.56, total_loss:1023.91\n",
      "epoch: 3 step:    0/6, lr:0.000100, giou_loss:  50.22, conf_loss: 869.68, prob_loss:  58.76, total_loss: 978.66\n",
      "epoch: 3 step:    1/6, lr:0.000100, giou_loss:  29.99, conf_loss: 830.75, prob_loss:  32.20, total_loss: 892.94\n",
      "\n",
      "\n",
      "giou_val_loss:  27.70, conf_val_loss:1779.83, prob_val_loss:  33.43, total_val_loss:1840.97\n",
      "\n",
      "\n",
      "epoch: 4 step:    2/6, lr:0.000100, giou_loss:  29.71, conf_loss: 812.82, prob_loss:  33.04, total_loss: 875.56\n",
      "epoch: 4 step:    3/6, lr:0.000100, giou_loss:  55.62, conf_loss: 833.83, prob_loss:  62.84, total_loss: 952.29\n",
      "epoch: 4 step:    4/6, lr:0.000100, giou_loss:  38.07, conf_loss: 756.36, prob_loss:  42.33, total_loss: 836.77\n",
      "epoch: 4 step:    5/6, lr:0.000100, giou_loss:  41.98, conf_loss: 732.60, prob_loss:  53.42, total_loss: 828.00\n",
      "epoch: 4 step:    0/6, lr:0.000100, giou_loss:  62.15, conf_loss: 715.14, prob_loss:  71.18, total_loss: 848.47\n",
      "epoch: 4 step:    1/6, lr:0.000100, giou_loss:  50.15, conf_loss: 699.40, prob_loss:  53.72, total_loss: 803.27\n",
      "\n",
      "\n",
      "giou_val_loss:  26.92, conf_val_loss:1752.22, prob_val_loss:  32.56, total_val_loss:1811.70\n",
      "\n",
      "\n",
      "epoch: 5 step:    2/6, lr:0.000100, giou_loss:  29.78, conf_loss: 682.16, prob_loss:  33.21, total_loss: 745.15\n",
      "epoch: 5 step:    3/6, lr:0.000100, giou_loss:  45.76, conf_loss: 672.89, prob_loss:  51.37, total_loss: 770.03\n",
      "epoch: 5 step:    4/6, lr:0.000100, giou_loss:  55.96, conf_loss: 662.14, prob_loss:  61.49, total_loss: 779.59\n",
      "epoch: 5 step:    5/6, lr:0.000100, giou_loss:  35.00, conf_loss: 632.30, prob_loss:  39.01, total_loss: 706.32\n",
      "epoch: 5 step:    0/6, lr:0.000100, giou_loss:  45.15, conf_loss: 630.20, prob_loss:  50.22, total_loss: 725.57\n",
      "epoch: 5 step:    1/6, lr:0.000100, giou_loss:  62.76, conf_loss: 622.33, prob_loss:  74.19, total_loss: 759.28\n",
      "\n",
      "\n",
      "giou_val_loss:  25.39, conf_val_loss:1718.01, prob_val_loss:  30.88, total_val_loss:1774.28\n",
      "\n",
      "\n",
      "epoch: 6 step:    2/6, lr:0.000100, giou_loss:  48.86, conf_loss: 596.74, prob_loss:  53.68, total_loss: 699.28\n",
      "epoch: 6 step:    3/6, lr:0.000099, giou_loss:  39.77, conf_loss: 601.96, prob_loss:  45.54, total_loss: 687.27\n",
      "epoch: 6 step:    4/6, lr:0.000099, giou_loss:  40.66, conf_loss: 612.26, prob_loss:  53.39, total_loss: 706.31\n",
      "epoch: 6 step:    5/6, lr:0.000099, giou_loss:  30.69, conf_loss: 562.82, prob_loss:  34.45, total_loss: 627.95\n",
      "epoch: 6 step:    0/6, lr:0.000099, giou_loss:  47.16, conf_loss: 568.61, prob_loss:  55.55, total_loss: 671.33\n",
      "epoch: 6 step:    1/6, lr:0.000099, giou_loss:  59.36, conf_loss: 586.04, prob_loss:  71.27, total_loss: 716.67\n",
      "\n",
      "\n",
      "giou_val_loss:  27.43, conf_val_loss:1678.28, prob_val_loss:  33.13, total_val_loss:1738.83\n",
      "\n",
      "\n",
      "epoch: 7 step:    2/6, lr:0.000099, giou_loss:  51.53, conf_loss: 550.72, prob_loss:  60.34, total_loss: 662.58\n",
      "epoch: 7 step:    3/6, lr:0.000099, giou_loss:  45.86, conf_loss: 532.25, prob_loss:  46.39, total_loss: 624.49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-77fd022b4df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcur_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
      "\u001b[0;32m<ipython-input-9-f6fb57ba5697>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(image_data, target)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgiou_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconf_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprob_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    593\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    594\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1242\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main\n",
    "best_val_loss = 1000 # should be large at start\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(image_data, target)\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "              .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "\n",
    "    if len(testset) == 0:\n",
    "        print(\"configure TEST options to validate model\")\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "        continue\n",
    "    \n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "    # writing validate summary data\n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "        \n",
    "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "\n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count)))\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/count:\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "        best_val_loss = total_val/count\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = next(trainset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 416, 416, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 52, 52, 3, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
