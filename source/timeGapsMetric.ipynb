{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "\n",
    "import healpy as hp\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "import lsst.sims.maf.db as db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to opsim database\n",
    "opsdb_baseline = db.OpsimDatabase('opsdb/baseline2018a.db')\n",
    "opsdb_pontus = db.OpsimDatabase('opsdb/pontus_2573.db')\n",
    "opsdb_baseline10yrs = db.OpsimDatabase('opsdb/baseline_2snap_v1.3_10yrs.db')\n",
    "\n",
    "# output directory\n",
    "outDir = 'outdir'\n",
    "resultsDb = db.ResultsDb(outDir=outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timeGapsMetric(metrics.BaseMetric):\n",
    "    \"\"\"\n",
    "    returns all time gaps between two filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                 filename='dT.pkl', fltpair=['y','i'],\n",
    "                 dataout=True, **kwargs):\n",
    "        self.colname = colname\n",
    "        self.filename = filename\n",
    "        self.fltpair = fltpair\n",
    "        self.dataout = dataout\n",
    "        \n",
    "        #if os.path.isfile(filename):\n",
    "            # rm old file\n",
    "        #    os.system(\"rm filename\")\n",
    "        \n",
    "        if self.dataout:\n",
    "            super().__init__(col=self.colname, metricDtype='object', **kwargs)\n",
    "        else:\n",
    "            super().__init__(col=self.colname, metricDtype='float', **kwargs)\n",
    "        \n",
    "    def dT(self, dataSlice, f0='i', f1='r'):\n",
    "        ''' return an array that contains all time gaps between two filters'''\n",
    "        idx0 = dataSlice['filter'] == f0\n",
    "        idx1 = dataSlice['filter'] == f1\n",
    "        \n",
    "        timeCol0 = dataSlice['observationStartMJD'][idx0]\n",
    "        timeCol1 = dataSlice['observationStartMJD'][idx1]\n",
    "\n",
    "        timeCol0 = timeCol0.reshape((len(timeCol0), 1))\n",
    "        timeCol1 = timeCol1.reshape((len(timeCol1), 1))\n",
    "\n",
    "        diffmat = np.abs( np.subtract(timeCol0, timeCol1.T) )\n",
    "\n",
    "        return diffmat.flatten()\n",
    "\n",
    "\n",
    "    def load_from_pkl(self, filename=\"test_pkl.pkl\"):\n",
    "        '''load dataframe from pickle'''\n",
    "        if os.path.isfile(filename):\n",
    "            df = pd.read_pickle(filename)\n",
    "        else:\n",
    "            df = pd.DataFrame()\n",
    "            df.to_pickle(filename)\n",
    "        return df\n",
    "    \n",
    "    def save_to_file(self, dic, filename=\"test_pkl.pkl\"):\n",
    "        '''save dict item to pickle file'''\n",
    "        \n",
    "        df = self.load_from_pkl(filename)\n",
    "\n",
    "        df = df.append(pd.DataFrame(dic), ignore_index=True)\n",
    "\n",
    "        df.to_pickle(filename)\n",
    "    \n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        # sort dataSlice\n",
    "        flt = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "        fdict = {'u':0, 'g':1, 'r':2, 'i':3, 'z':4, 'y':5}\n",
    "\n",
    "        dataSlice.sort(order='observationStartMJD')\n",
    "\n",
    "        dT = self.dT(dataSlice, f0=self.fltpair[0], f1=self.fltpair[1])\n",
    "        #print(type(dataSlice['fieldRA']), dataSlice['fieldDec'])\n",
    "        #dT_list = []\n",
    "        #for i in range(len(dataSlice['fieldRA'])):\n",
    "        #   dT_list.append(dT)\n",
    "        \n",
    "        dic = {'ra':np.mean(dataSlice['fieldRA']), 'dec':np.mean(dataSlice['fieldDec']), 'dT': [dT]}\n",
    "        # print(dic)\n",
    "        # save to file\n",
    "        self.save_to_file(dic, self.filename)\n",
    "        \n",
    "        # return dT\n",
    "        if self.dataout:\n",
    "            result = dT\n",
    "            return result\n",
    "        else:\n",
    "            f0 = self.fltpair[0]\n",
    "            f1 = self.fltpair[1]\n",
    "            result = np.min(dT) if len(dT)!=0 else np.inf\n",
    "            return float(result)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the metric, check same filename in folder\n",
    "metric = timeGapsMetric(colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                          filename='dT_ri.pkl', fltpair=['r','i'], dataout=False)\n",
    "slicer = slicers.HealpixSlicer(nside=16)\n",
    "\n",
    "sqlconstraint = 'night<400'\n",
    "metricSky = metricBundles.MetricBundle(metric,slicer,sqlconstraint)\n",
    "\n",
    "group = metricBundles.MetricBundleGroup({'metricSky':metricSky}, opsdb_pontus, outDir=outDir, resultsDb=resultsDb)\n",
    "group.runAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for all filter pairs\n",
    "\n",
    "slicer = slicers.HealpixSlicer(nside=16)\n",
    "\n",
    "sqlconstraint = 'night<400'\n",
    "\n",
    "# create an dict to run metric for all pairs\n",
    "metricSkyDict = {}\n",
    "flt = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "for i, f0 in enumerate(flt):\n",
    "    for f1 in flt[i:]:\n",
    "        filename = 'dT_{}{}_pontus.pkl'.format(f0, f1)\n",
    "        fltpair = [f0, f1]\n",
    "        metric = timeGapsMetric(colname=['observationStartMJD', 'filter', 'fiveSigmaDepth'], \n",
    "                          filename=filename, fltpair=fltpair, dataout=False)\n",
    "        \n",
    "        metricSky = metricBundles.MetricBundle(metric,slicer,sqlconstraint)\n",
    "        metricSkyname = 'metricSky_{}{}'.format(f0, f1)\n",
    "        metricSkyDict[metricSkyname] = metricSky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = metricBundles.MetricBundleGroup(metricSkyDict, opsdb_pontus, outDir=outDir, resultsDb=resultsDb)\n",
    "group.runAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all histogram\n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(24, 24)); # 6 axes on a 2x3 grid\n",
    "\n",
    "flt = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "fdict = {'u':0, 'g':1, 'r':2, 'i':3, 'z':4, 'y':5}\n",
    "tlim = 1.5 # in hours\n",
    "for i, f0 in enumerate(flt):\n",
    "    for f1 in flt[i:]:\n",
    "        dT = np.concatenate(df.dT)\n",
    "        filename = 'dT_{}{}_pontus.pkl'.format(f0, f1)\n",
    "        df = pd.read_pickle(filename)\n",
    "        dT = np.concatenate(df.dT)\n",
    "        # dT = dT[dT!=0]\n",
    "        #axs[fdict[f0], fdict[f1]].hist(dT[dT<1/24],bins=100); \n",
    "        if f0==f1:\n",
    "            axs[fdict[f0], fdict[f1]].hist(dT[dT<tlim/24]*24,bins=100); \n",
    "            axs[fdict[f0], fdict[f1]].set_xlabel(f0+f1)\n",
    "        else:\n",
    "            axs[fdict[f0], fdict[f1]].axis('off')\n",
    "            axs[fdict[f1], fdict[f0]].hist(dT[dT<tlim/24]*24,bins=100);        \n",
    "            axs[fdict[f1], fdict[f0]].set_xlabel(f0+f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot skymap \n",
    "\n",
    "fig, axs = plt.subplots(6, 6, figsize=(24, 24), \n",
    "                        subplot_kw={'projection': 'mollweide'}); # 6 axes on a 2x3 grid\n",
    "\n",
    "for i, f0 in enumerate(flt):\n",
    "    for f1 in flt[i:]:\n",
    "    \n",
    "    plot_mwd(axs[1,1], df.ra.values, df.dec.values, df['dT'].apply(get_tmin).values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
